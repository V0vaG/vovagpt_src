FROM python:3.11-slim

WORKDIR /app

# Install system dependencies including Ollama
RUN apt-get update && apt-get install -y \
    curl \
    ca-certificates \
    supervisor \
    && rm -rf /var/lib/apt/lists/*

# Install Ollama
RUN curl -fsSL https://ollama.com/install.sh | sh

# Copy requirements and install Python dependencies
COPY app/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY app/ .

# Create data directory and ollama directory
RUN mkdir -p /root/script_files/vovagpt/data
RUN mkdir -p /root/.ollama

# Create supervisor config to run both Ollama and Flask
RUN echo '[supervisord]\n\
nodaemon=true\n\
logfile=/dev/null\n\
logfile_maxbytes=0\n\
\n\
[program:ollama]\n\
command=/usr/local/bin/ollama serve\n\
environment=OLLAMA_HOST="0.0.0.0:11434",OLLAMA_MODELS="/root/.ollama/models"\n\
autostart=true\n\
autorestart=true\n\
stdout_logfile=/dev/stdout\n\
stdout_logfile_maxbytes=0\n\
stderr_logfile=/dev/stderr\n\
stderr_logfile_maxbytes=0\n\
\n\
[program:flask]\n\
command=gunicorn -w 4 -b 0.0.0.0:5000 --timeout 120 wsgi:app\n\
environment=OLLAMA_HOST="http://localhost:11434",VERSION="2.0.0",PYTHONUNBUFFERED="1"\n\
autostart=true\n\
autorestart=true\n\
stdout_logfile=/dev/stdout\n\
stdout_logfile_maxbytes=0\n\
stderr_logfile=/dev/stderr\n\
stderr_logfile_maxbytes=0\n\
' > /etc/supervisor/conf.d/supervisord.conf

# Expose ports
EXPOSE 5000 11434

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV FLASK_APP=app.py
ENV OLLAMA_HOST=http://localhost:11434

# Run supervisor to manage both processes
CMD ["/usr/bin/supervisord", "-c", "/etc/supervisor/conf.d/supervisord.conf"]

